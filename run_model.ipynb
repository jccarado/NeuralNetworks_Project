{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import math, os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from model import Autoencoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from sklearn import metrics\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad('data/gene_sorted_filtered_matrix.h5ad').T\n",
    "barcodes = pd.read_csv('data/barcodes_filtered.tsv', header=None, sep='\\t')\n",
    "genes = pd.read_csv('data/genes.tsv', header=None, sep='\\t')\n",
    "ground_truth_labels = pd.read_csv('data/ground_truth_labels.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following scdeepcluster here, encoding labels to ints and attaching to the anndata object\n",
    "\n",
    "adata.obs_names = barcodes[0].values\n",
    "adata.var_names = genes[0].values\n",
    "\n",
    "ground_truth_labels = ground_truth_labels.set_index(\"NAME\")  \n",
    "y = pd.Categorical(adata.obs_names.map(ground_truth_labels[\"New_cellType\"])).codes\n",
    "\n",
    "adata.obs['Group'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard filtering from scanpy workflow, this is also what our baseline used, we could consider tweaking this though\n",
    "\n",
    "sc.pp.filter_cells(adata, min_genes=100)\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "print(adata.shape)\n",
    "print(adata.n_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZINB loss uses size factors and raw X values\n",
    "# after saving those, normalize counts\n",
    "\n",
    "adata.obs['n_counts'] = adata.X.sum(axis=1).A1  \n",
    "adata.obs['size_factors'] = adata.obs.n_counts / np.median(adata.obs.n_counts)\n",
    "\n",
    "adata.X = adata.X.toarray()\n",
    "\n",
    "adata.raw = adata.copy()\n",
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model args, defaults from scdeepcluster\n",
    "# hyperparameter tuning on these?\n",
    "\n",
    "input_dim = adata.n_vars\n",
    "encoder_layers = [256, 64]\n",
    "z_dim = 32\n",
    "decoder_layers = [64, 256]\n",
    "\n",
    "device = 'cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "\n",
    "model = Autoencoder(input_dim=adata.n_vars, z_dim=z_dim, encoder_layers=encoder_layers, decoder_layers=decoder_layers, device='cpu')\n",
    "print(str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained weights if they exist, otherwise do pretraining step\n",
    "\n",
    "\n",
    "if os.path.isfile('AE_weights.pth.tar'):\n",
    "    print(\"Loading pretrained model weights\")\n",
    "    checkpoint = torch.load('AE_weights.pth.tar')\n",
    "    model.load_state_dict(checkpoint['ae_state_dict'])\n",
    "else:\n",
    "    model.pretrain(X=adata.X, X_raw=adata.raw.X, size_factor=adata.obs.size_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "\n",
    "# Everything after this is more exploratory on how the model runs with knowing or not knowing n_clusters, how centroids are initialized, etc\n",
    "# so its kind of messy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before using the autoencoder clustering layer to make predictions, i wanted to see what leiden alg would do on the latent space\n",
    "\n",
    "\n",
    "\n",
    "# convert latent representation into Anndata object, do knn and leiden (resolution tweaked to 14 clusters), plot\n",
    "# on input: do pca, knn, leiden\n",
    "# the idea here was to compare linear and non linear embedding, but still use leiden to actually cluster\n",
    "\n",
    "# baseline:     pca->knn->leiden\n",
    "# ae:        latent->knn->leiden\n",
    "\n",
    "pretrain_latent = model.encodeBatch(torch.tensor(adata.X, dtype=torch.float64)).cpu().numpy()\n",
    "adata_latent = sc.AnnData(pretrain_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata_latent)\n",
    "sc.tl.leiden(adata_latent, flavor=\"igraph\", n_iterations=2, resolution=0.3)\n",
    "sc.tl.umap(adata_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.pca(adata)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.leiden(adata, flavor=\"igraph\", n_iterations=2, resolution=0.8)\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# leiden clustering on latent representation\n",
    "sc.pl.umap(adata_latent, color=\"leiden\", ax=ax[0], title=\"Latent Cluster Predictions\", show=False)\n",
    "\n",
    "# leiden clustering on PCs (same as baseline)\n",
    "sc.pl.umap(adata, color=\"leiden\", ax=ax[1], title=\"PCA-based Cluster Predictions\", show=False)\n",
    "\n",
    "# 3. Ground truth labels\n",
    "sc.pl.umap(adata, color=\"Group\", ax=ax[2], title=\"Ground Truth Clusters\", show=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is taking the results of leiden clustering on the latent space and getting n_clusters and cluster_centers\n",
    "# n_clusters and cluster_centers are used in the clustering phase of the autoencoder below\n",
    "\n",
    "y_pred_init = np.asarray(adata_latent.obs['leiden'],dtype=int)\n",
    "features = pd.DataFrame(adata_latent.X,index=np.arange(0,adata_latent.n_obs))\n",
    "Group = pd.Series(y_pred_init,index=np.arange(0,adata_latent.n_obs),name=\"Group\")\n",
    "Mergefeature = pd.concat([features,Group],axis=1)\n",
    "cluster_centers = np.asarray(Mergefeature.groupby(\"Group\").mean())\n",
    "n_clusters = cluster_centers.shape[0]\n",
    "print('Estimated number of clusters: ', n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run clustering phase using n_clusters, cluster_centers, and y_pred_init from above cell\n",
    "# in scdeepcluster, this is how the model is run when ground truth labels are no provided (therefore n_clusters has to be estimated using above cell)\n",
    "# this copies line 145 on run_scdeepcluster.py\n",
    "\n",
    "y_pred, _, _, _ = model.fit(X=adata.X, X_raw=adata.raw.X, size_factor=adata.obs.size_factors, n_clusters=n_clusters, init_centroid=cluster_centers, \n",
    "            y_pred_init=y_pred_init, y=y, num_epochs=300)\n",
    "\n",
    "\n",
    "\n",
    "# run clustering phase using n_clusters which is known from provided ground truth labels\n",
    "# cluster_centers and y_pred_init are found with kmeans - model.py line 136\n",
    "# this copies line 130 on run_scdeepcluster.py\n",
    "# \n",
    "# y_pred, _, _, _ = model.fit(X=adata.X, X_raw=adata.raw.X, size_factor=adata.obs.size_factors, n_clusters=n_clusters, init_centroid=cluster_centers, \n",
    "#            y_pred_init=y_pred_init, y=y, num_epochs=300)            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final metrics\n",
    "\n",
    "ami = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)\n",
    "ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "print('Evaluating cells: AMI= %.4f, ARI= %.4f' % (ami, ari))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot clustering phase results\n",
    "\n",
    "adata.obs['y_pred'] = y_pred.astype(str)\n",
    "adata.obs['Group'] = y.astype(str)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Clustering phase predictions\n",
    "sc.pl.umap(adata, color=\"y_pred\", ax=ax[0], title=\"Cluster Predictions\", show=False)\n",
    "\n",
    "# Ground truth labels\n",
    "sc.pl.umap(adata, color=\"Group\", ax=ax[1], title=\"Ground Truth Clusters\", show=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
